---
title: "Test_Github_R"
output: html_notebook
---

Download all the packages that are needed for the code to run 
```{r}
# Download packages needed:
# DESeq for analysis of differential expression
if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")

BiocManager::install("DESeq")
install.packages("venneuler")
install.packages("VennDiagram")
```

The packages are then loaded using library()

```{r}
library('DESeq')
library(stringr) # Needed to extract data of interest from counts from Artremis
library(dplyr) # allows row comparisons
library(VennDiagram)
library(RColorBrewer)
```


```{r}
#setwd("~/Johannas_Rcode")
```

where this directory should push to git. We then load the we are interested using the read.table and change direct

```{r}
# Download the files
raw_0h = read.table("~/Johannas_Rcode/results/mapping_results/counts_values_0h.txt", sep = "\t", header = TRUE, row.names = 1)
raw_30min = read.table("~/Johannas_Rcode/results/mapping_results/counts_values_30min.txt", sep = "\t", header = TRUE, row.names = 1)
raw_6h = read.table("~/Johannas_Rcode/results/mapping_results/counts_values_6h.txt", sep = "\t", header = TRUE, row.names = 1)
raw_24h = read.table("~/Johannas_Rcode/results/mapping_results/counts_values_24h.txt", sep = "\t", header = TRUE, row.names = 1)
```

When doing this import, a data.frame consisting of the sense, antisense and total counts is generated. Since we are only interested in the total counts, which is the last "word" in a string, we can extract this part using the "stringr" package. Followed by this, we set the row and colnames to the same as before, and merge data from all time points with that of the 0hr samples. We then remove the total counts to not have to many things saved in our environment. 

```{r}
# Extracting only total counts

# for 0h counts
counts_values_0h_total = 
  data.frame(as.integer(str_extract(raw_0h[-1,]$ERR405224.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_0h[-1,]$ERR405225.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_0h[-1,]$ERR405226.sorted.bam, "\\w+$")))

colnames(counts_values_0h_total) = colnames(raw_0h[1:3])
rownames(counts_values_0h_total) = rownames(raw_0h[-1,]) 

# for 30 min
counts_values_30min_total =
  data.frame(as.integer(str_extract(raw_30min[-1,]$ERR405227.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_30min[-1,]$ERR405228.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_30min[-1,]$ERR405229.sorted.bam, "\\w+$")))
# the raw_0h[-1,] removes the row giving the "total" header for each column in 30 min sample
colnames(counts_values_30min_total) = colnames(raw_30min[1:3])
rownames(counts_values_30min_total) = rownames(raw_30min[-1,])

# for 6h
counts_values_6h_total = 
  data.frame(as.integer(str_extract(raw_6h[-1,]$mapped_ERR405230.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_6h[-1,]$mapped_ERR405231.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_6h[-1,]$mapped_ERR405232.sorted.bam, "\\w+$")))

colnames(counts_values_6h_total) = colnames(raw_6h[1:3])
rownames(counts_values_6h_total) = rownames(raw_6h[-1,])

# for 24h 
counts_values_24h_total = 
  data.frame(as.integer(str_extract(raw_24h[-1,]$mapped_ERR405233.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_24h[-1,]$mapped_ERR405234.sorted.bam,"\\w+$")),
             as.integer(str_extract(raw_24h[-1,]$mapped_ERR405235.sorted.bam, "\\w+$")))

colnames(counts_values_24h_total) = colnames(raw_24h[1:3])
rownames(counts_values_24h_total) = rownames(raw_24h[-1,])

# Merge the 0h controll with the counts for other time points
raw_counts_30min_0h = data.frame(counts_values_0h_total, counts_values_30min_total)
raw_counts_6h_0h = data.frame(counts_values_0h_total, counts_values_6h_total)
raw_counts_24h_0h = data.frame(counts_values_0h_total, counts_values_24h_total)
rm(counts_values_30min_total, counts_values_6h_total, counts_values_24h_total)
```

Following the installation, the DESeq analysis is run. To do so, we specify what columns correspond to a given condition, i.e. compare data from time 0 and time 0.5h samples. The procedure of doing the DEseq is taken from the vignette("DESeq") file available at:  http://15.236.44.5:8787/files/R/x86_64-pc-linux-gnu-library/3.6/DESeq/doc/DESeq.pdf

NOTE: We could filter low counts to make the algorithm faster and better, since genes which have only been counted 1-2 time for any samples will not give any information. However, the DESeq has a filtering 
```{r}
condition_30min = factor(c("0h","0h","0h","0.5h","0.5h","0.5h"))
condition_6h = factor(c("0h","0h","0h","6h","6h","6h"))
condition_24h = factor(c("0h","0h","0h","24h","24h","24h"))

count_ds_30min = newCountDataSet(countData = raw_counts_30min_0h, condition_30min)
count_ds_6h = newCountDataSet(countData = raw_counts_6h_0h, condition_6h)
count_ds_24h = newCountDataSet(countData = raw_counts_24h_0h, condition_24h)

```

The newCountDataSet is then used to calculate the size factors and estimateDispersion for all the times, and we look at this fitted model using plotDispEsts to see how good the linear model of DESeq caprutred our data. 
```{r}
# For the 30 min
count_ds_30min = estimateSizeFactors(count_ds_30min)
sizeFactors(count_ds_30min)
head(counts(count_ds_30min, normalized=TRUE))
count_ds_30min = estimateDispersions(count_ds_30min)

# For 6h
count_ds_6h = estimateSizeFactors(count_ds_6h)
sizeFactors(count_ds_6h)
head(counts(count_ds_6h, normalized=TRUE))
count_ds_6h = estimateDispersions(count_ds_6h)

# For 24h
count_ds_24h = estimateSizeFactors(count_ds_24h)
sizeFactors(count_ds_24h)
head(counts(count_ds_24h, normalized=TRUE))
count_ds_24h = estimateDispersions(count_ds_24h)
#str(fitInfo(count_ds_6h))
#plotDispEsts(count_ds_6h) # Gives the fitted dispersion vs normalized mean to see fit
```

To compare our data from the DE analysis, the results command is used with a "nbinomTest" to caluclate log-changes etc. 
This gives an output in the following form:
id                -      feature identifier
baseMean          -     mean normalised counts, averaged over all samples from both conditions
baseMeanA         -     mean normalised counts from condition A (0hr)
baseMeanB         -     mean normalised counts from condition B (given timepoint)
foldChange        -     fold change from condition A to B
log2FoldChange    -     the logarithm (to basis 2) of the fold change
pval              -     p value for the statistical significance of this change
padj              -     p value adjusted for multiple testing with the Benjamini-Hochberg procedure (see the R function p.adjust), which controls false discovery rate (FDR)



```{r}
#modelled_data = DESeq(modelled_data)
result_30min = nbinomTest(count_ds_30min, "0h", "0.5h" ) # Calculate logFC + p 
result_30min = data.frame(result_30min, row.names = 1) # set gene names as row names in the results table

result_6h = nbinomTest(count_ds_6h, "0h", "6h" ) # Calculate logFC + p 
result_6h = data.frame(result_6h, row.names = 1) # set gene names as row names in the results table

result_24h = nbinomTest(count_ds_24h, "0h", "24h" ) # Calculate logFC + p 
result_24h = data.frame(result_24h, row.names = 1)
```

To do the metabolic profiling, we create a subset for all the genes that have been differentially expressed based on the FDR cutoff = 0.05. This also gives us the number of differential expressed genes.
```{r}
#extract significant with FDR < 0.05
significant_genes_30min = subset(result_30min,result_30min$padj<0.05) 
significant_genes_6h = subset(result_6h,result_6h$padj<0.05)
significant_genes_24h = subset(result_24h,result_24h$padj<0.05)
number_DE = data.frame((cbind(nrow(significant_genes_30min),nrow(significant_genes_6h),nrow(significant_genes_24h))),( cbind(nrow(significant_genes_30min)/575,nrow(significant_genes_6h)/5078,
nrow(significant_genes_24h)/1483))*100)

#number_DE = rbind(DE_genes, percentage_DE*100)

colnames(number_DE) = cbind("30 min", "6h", "24h")
rownames(number_DE) = rbind("Number differentially expressed genes", "Percentage of original DE number")
print(number_DE) 

# Save the results to use in the metabollic profiling step
#write.table(significant_genes_30min, file ="sig_30", sep = "\t" )
#write.table(significant_genes_6h, file ="sig_6h", sep = "\t" )
#write.table(significant_genes_24h, file ="sig_24h", sep = "\t" )

```
Worth to note from this is that all the gotten values are smaller than the ones from the article, which where 575, 2078 and 1486 genes differentially expressed in the original study. 

```{r}
# Order data by adjusted p-value
ordered.counts_30min = order(result_30min$padj,decreasing = FALSE)
ordered.counts_6h = order(result_6h$padj,decreasing = FALSE)
ordered.counts_24h = order(result_24h$padj,decreasing = FALSE)

# make new table based on order
results.ordered_30min = result_30min[ordered.counts_30min,]
results.ordered_6h = result_6h[ordered.counts_6h,]
results.ordered_24h = result_24h[ordered.counts_24h,]

# rm order matrix 
rm(ordered.counts_30min,ordered.counts_6h,ordered.counts_24h)
```
From the raw counts, we now want to compare the differentially expressed genes using a heatmap. This done as below. 

- How to choose the 0 values? 
```{r}
# view results using heatmap
# based on criteria of 239 genes with >2-fold change... 
more_than_2fold_30 = subset(significant_genes_30min,significant_genes_30min$foldChange>2)
more_than_2fold_6h = subset(significant_genes_6h,significant_genes_6h$foldChange>2)
more_than_2fold_24 = subset(significant_genes_24h,significant_genes_24h$foldChange>2)

#Take average expression for the 0 counts?
baseMeansA= cbind(result_30min$baseMeanA, result_6h$baseMeanA, results.ordered_24h$baseMeanA)
counts0 = data.frame(apply(baseMeansA,1,mean))

counts_matrix = as.matrix(cbind(counts0$apply.baseMeansA..1..mean.,more_than_2fold_30$baseMeanB, more_than_2fold_6h$baseMeanB, more_than_2fold_24$baseMeanB))


#rownames(counts_matrix) = rownames(significant_genes_30min)
#install.packages("gplots")
#if (!require("RColorBrewer")) {
#install.packages("RColorBrewer")
#}

#library(gplots)
#library(RColorBrewer)
#mypalette = brewer.pal(11,"RdYlBu") 
#morecols = colorRampPalette(mypalette) 
#mycols=rev(morecols(255))

#column.cols=c("purple","orange")[condition] 
#heatmap.2(counts_matrix,trace='none',col=mycols,main='The 100 most significant genes',ColSideColors=column.cols, ) 

heatmap(counts_matrix, xlab = 'time', ylab = 'genes')
```
Find the matching genes between times

```{r}

genelist_30min = data.frame(rownames(significant_genes_30min))
colnames(genelist_30min) = "GeneID"

genelist_6h = data.frame(rownames(significant_genes_6h))
colnames(genelist_6h) = "GeneID"

genelist_24h = data.frame(rownames(significant_genes_24h))
colnames(genelist_24h) = "GeneID"


genelist_all = data.frame(intersect(intersect(genelist_24h$GeneID,genelist_6h$GeneID),genelist_30min$GeneID))

```


Download and create Venn diagram


```{r}

set_30 = as.character(genelist_30min$GeneID)
set_6h = as.character(genelist_6h$GeneID)
set_24h = as.character(genelist_24h$GeneID)

myCol <- brewer.pal(3, "Pastel2")

# Chart
venn.diagram(
        x = list(set_30, set_6h, set_24h),
        category.names = c("30 min" , "6h " , "24h"),
        filename = 'test_venn.png',
        output=TRUE,
        
        # Output features
        imagetype="png" ,
        height = 480 , 
        width = 480 , 
        resolution = 300,
        compression = "lzw",
        
        # Circles
        lwd = 2,
        lty = 'blank',
        fill = myCol,
        
        # Numbers
        cex = .6,
        fontface = "bold",
        fontfamily = "sans",
        
        # Set names
        cat.cex = 0.6,
        cat.fontface = "bold",
        cat.default.pos = "outer",
        cat.pos = c(-27, 27, 135),
        cat.dist = c(0.055, 0.055, 0.085),
        cat.fontfamily = "sans",
        rotation = 1
)
```





